{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules for cleansing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Packages.DataPreperation import CleanData\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from textblob import TextBlob as txt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import time\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimentData = pd.read_csv(r\"Data\\IMDB Dataset.csv\")\n",
    "sentimentData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for the distribution of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25000\n",
       "1    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentiment2 = sentimentData\n",
    "\n",
    "Sentiment2['sentiment'] = Sentiment2['sentiment'].replace(\"negative\", 0)\n",
    "Sentiment2['sentiment'] = Sentiment2['sentiment'].replace(\"positive\", 1)\n",
    "\n",
    "Sentiment2['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentimentData['sentiment'].value_counts().plot.bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleansing initialised.\n"
     ]
    }
   ],
   "source": [
    "perform = CleanData()\n",
    "\n",
    "removeEmojis = True\n",
    "CleanText = True\n",
    "removeStopWords = True\n",
    "lemmatizeText = True\n",
    "POSLemmatizeTextFor = False\n",
    "Stemtextfor = False\n",
    "textcol = \"review\"\n",
    "\n",
    "if CleanText == True:\n",
    "    Sentiment2 = perform.GeneralCleansingFor(Sentiment2, textcol)\n",
    "if removeEmojis == True:\n",
    "    Sentiment2 = perform.RemoveEmoticonsFor(Sentiment2)\n",
    "if removeStopWords == True:\n",
    "    Sentiment2 = perform.RemoveStopWordsFor(Sentiment2)\n",
    "if lemmatizeText == True:\n",
    "    Sentiment2 = perform.LemmatizeTextFor(Sentiment2)\n",
    "if POSLemmatizeTextFor == True:\n",
    "    Sentiment2 = perform.POSLemmatizeTextFor(Sentiment2)\n",
    "if Stemtextfor == True:\n",
    "    Sentiment2 = perform.StemTextFor(Sentiment2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform tokenisation and create test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(r\"[a-zA-Z0-9]+\")\n",
    "cv = CountVectorizer(stop_words=\"english\",ngram_range=(1,1),tokenizer=token.tokenize)\n",
    "text_counts = cv.fit_transform(Sentiment2[\"newReview\"])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, Sentiment2[\"sentiment\"], test_size=0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 86.14%\n",
      "precision: 88.0\n",
      "recall: 84.0\n",
      "F1: 86.0\n",
      "confusion matrix: \n",
      "[[5412  737]\n",
      " [ 996 5355]]\n"
     ]
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train,Y_train)\n",
    "predicted = MNB.predict(X_test)\n",
    "accuracy_score = metrics.accuracy_score(predicted, Y_test)\n",
    "print(\"accuracy: \" + str('{:4.2f}'.format(accuracy_score*100))+'%')\n",
    "\n",
    "macro_precision = (metrics.precision_score(Y_test, predicted, average='binary'))\n",
    "macro_precision = (round(macro_precision,2))*100\n",
    "print(\"precision: \" + str(macro_precision))\n",
    "\n",
    "macro_recall = (metrics.recall_score(Y_test, predicted, average='binary'))\n",
    "macro_recall = (round(macro_recall,2))*100\n",
    "print(\"recall: \" + str(macro_recall))\n",
    "\n",
    "macro_f1 = (metrics.f1_score(Y_test, predicted, average='binary'))\n",
    "macro_f1 = (round(macro_f1,2))*100\n",
    "print(\"F1: \" + str(macro_f1))\n",
    "\n",
    "conf_mat = confusion_matrix(Y_test, predicted)\n",
    "print(\"confusion matrix: \\n\" + str(conf_mat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      6149\n",
      "           1       0.88      0.84      0.86      6351\n",
      "\n",
      "    accuracy                           0.86     12500\n",
      "   macro avg       0.86      0.86      0.86     12500\n",
      "weighted avg       0.86      0.86      0.86     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  88.208 %\n",
      "88.0\n",
      "89.0\n",
      "88.0\n",
      "[[5377  772]\n",
      " [ 702 5649]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver = 'liblinear', random_state = 42, max_iter=1000)\n",
    "lr.fit(X_train,Y_train)\n",
    "lg_pred = lr.predict(X_test)\n",
    "print(\"Accuracy: \",round((metrics.accuracy_score(Y_test,lg_pred))*100,3),\"%\")\n",
    "\n",
    "macro_precision = (metrics.precision_score(Y_test, lg_pred, average='binary'))\n",
    "macro_precision = (round(macro_precision,2))*100\n",
    "print(macro_precision)\n",
    "\n",
    "macro_recall = (metrics.recall_score(Y_test, lg_pred, average='binary'))\n",
    "macro_recall = (round(macro_recall,2))*100\n",
    "print(macro_recall)\n",
    "\n",
    "macro_f1 = (metrics.f1_score(Y_test, lg_pred, average='binary'))\n",
    "macro_f1 = (round(macro_f1,2))*100\n",
    "print(macro_f1)\n",
    "\n",
    "conf_mat = confusion_matrix(Y_test, lg_pred)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      6149\n",
      "           1       0.88      0.89      0.88      6351\n",
      "\n",
      "    accuracy                           0.88     12500\n",
      "   macro avg       0.88      0.88      0.88     12500\n",
      "weighted avg       0.88      0.88      0.88     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, lg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "\n",
    "try wordvec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matrix for k = 1 is:\n",
      "\n",
      "[[3621 2528]\n",
      " [2255 4096]]\n",
      "\n",
      "Classification Report for k = 1 is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.60      6149\n",
      "           1       0.62      0.64      0.63      6351\n",
      "\n",
      "    accuracy                           0.62     12500\n",
      "   macro avg       0.62      0.62      0.62     12500\n",
      "weighted avg       0.62      0.62      0.62     12500\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix for k = 2 is:\n",
      "\n",
      "[[5016 1133]\n",
      " [3794 2557]]\n",
      "\n",
      "Classification Report for k = 2 is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.82      0.67      6149\n",
      "           1       0.69      0.40      0.51      6351\n",
      "\n",
      "    accuracy                           0.61     12500\n",
      "   macro avg       0.63      0.61      0.59     12500\n",
      "weighted avg       0.63      0.61      0.59     12500\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix for k = 3 is:\n",
      "\n",
      "[[3852 2297]\n",
      " [2367 3984]]\n",
      "\n",
      "Classification Report for k = 3 is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.62      6149\n",
      "           1       0.63      0.63      0.63      6351\n",
      "\n",
      "    accuracy                           0.63     12500\n",
      "   macro avg       0.63      0.63      0.63     12500\n",
      "weighted avg       0.63      0.63      0.63     12500\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix for k = 4 is:\n",
      "\n",
      "[[4825 1324]\n",
      " [3413 2938]]\n",
      "\n",
      "Classification Report for k = 4 is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.78      0.67      6149\n",
      "           1       0.69      0.46      0.55      6351\n",
      "\n",
      "    accuracy                           0.62     12500\n",
      "   macro avg       0.64      0.62      0.61     12500\n",
      "weighted avg       0.64      0.62      0.61     12500\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix for k = 5 is:\n",
      "\n",
      "[[3997 2152]\n",
      " [2474 3877]]\n",
      "\n",
      "Classification Report for k = 5 is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.63      6149\n",
      "           1       0.64      0.61      0.63      6351\n",
      "\n",
      "    accuracy                           0.63     12500\n",
      "   macro avg       0.63      0.63      0.63     12500\n",
      "weighted avg       0.63      0.63      0.63     12500\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix for k = 6 is:\n",
      "\n",
      "[[4761 1388]\n",
      " [3216 3135]]\n",
      "\n",
      "Classification Report for k = 6 is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.77      0.67      6149\n",
      "           1       0.69      0.49      0.58      6351\n",
      "\n",
      "    accuracy                           0.63     12500\n",
      "   macro avg       0.64      0.63      0.63     12500\n",
      "weighted avg       0.65      0.63      0.62     12500\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix for k = 7 is:\n",
      "\n",
      "[[4096 2053]\n",
      " [2489 3862]]\n",
      "\n",
      "Classification Report for k = 7 is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.64      6149\n",
      "           1       0.65      0.61      0.63      6351\n",
      "\n",
      "    accuracy                           0.64     12500\n",
      "   macro avg       0.64      0.64      0.64     12500\n",
      "weighted avg       0.64      0.64      0.64     12500\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix for k = 8 is:\n",
      "\n",
      "[[4746 1403]\n",
      " [3072 3279]]\n",
      "\n",
      "Classification Report for k = 8 is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.68      6149\n",
      "           1       0.70      0.52      0.59      6351\n",
      "\n",
      "    accuracy                           0.64     12500\n",
      "   macro avg       0.65      0.64      0.64     12500\n",
      "weighted avg       0.65      0.64      0.64     12500\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix for k = 9 is:\n",
      "\n",
      "[[4182 1967]\n",
      " [2497 3854]]\n",
      "\n",
      "Classification Report for k = 9 is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.65      6149\n",
      "           1       0.66      0.61      0.63      6351\n",
      "\n",
      "    accuracy                           0.64     12500\n",
      "   macro avg       0.64      0.64      0.64     12500\n",
      "weighted avg       0.64      0.64      0.64     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "prec_list = []\n",
    "rec_list = []\n",
    "f1_list = []\n",
    "for k in range(1,10):\n",
    "\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k,algorithm='brute') #Using brute-force algorithm for quicker computation.\n",
    "    classifier.fit(X_train, Y_train) #Fitting the built-in sklearn classifier on our training data\n",
    "    kPred = classifier.predict(X_test) #Making the classifier to predict on the previously unseen test data.\n",
    "\n",
    "    accuracy_score = (metrics.accuracy_score(Y_test,kPred))\n",
    "    accuracy_score = (round(accuracy_score,2))*100\n",
    "    acc_list.append(accuracy_score)\n",
    "\n",
    "    confusion_mat = confusion_matrix(Y_test, kPred)\n",
    "    class_report = classification_report(Y_test, kPred)\n",
    "\n",
    "    macro_precision = (metrics.precision_score(Y_test, kPred, average='binary'))\n",
    "    macro_precision = (round(macro_precision,2))*100\n",
    "    prec_list.append(macro_precision)\n",
    "\n",
    "    macro_recall = (metrics.recall_score(Y_test, kPred, average='binary'))\n",
    "    macro_recall = (round(macro_recall,2))*100\n",
    "    rec_list.append(macro_recall)\n",
    "    \n",
    "    macro_f1 = (metrics.f1_score(Y_test, kPred, average='binary'))\n",
    "    macro_f1 = (round(macro_f1,2))*100\n",
    "    f1_list.append(macro_f1)\n",
    "\n",
    "    print(\"\\n\\nConfusion Matrix for k = {} is:\\n\".format(k))\n",
    "    print(confusion_mat)\n",
    "    print(\"\\nClassification Report for k = {} is:\\n\".format(k))\n",
    "    print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85      6149\n",
      "           1       0.86      0.86      0.86      6351\n",
      "\n",
      "    accuracy                           0.86     12500\n",
      "   macro avg       0.86      0.86      0.86     12500\n",
      "weighted avg       0.86      0.86      0.86     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svmModel = svm.SVC(kernel='linear')\n",
    "\n",
    "svmModel.fit(X_train, Y_train)\n",
    "\n",
    "svmPred = svmModel.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, svmPred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
